{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NLP library ,for preprocessing of text\n",
    "import nltk\n",
    "#for numerical computations\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to implement word embeddings ,word to vector or load the built model.\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pre trained word2vec (word to vector) model \n",
    "#I downloaded bin file from https://ibm.ent.box.com/s/77etivy69jmga0x0u6vs2n47ul8baks4\n",
    "\n",
    "model_pre_process=gensim.models.Word2Vec.load(\"E:\\India_AI\\word2vec.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#took very simple training data\n",
    "#x=[\"Hi\",\"How are you\",\"I am also good\",\"what are the stages in the comptition?\",\"ok\"]\n",
    "#y=[\"Hi\",\"I am doing well\" ,\"how about you\",\"That's good to hear,so what do you want to know\",\"well,one is idea submission round,second is Build\",\"All the best\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "sourcefile=open(\"E:\\\\India_AI\\\\conversation.json\",\"rU\")\n",
    "conversation_data=json.load(sourcefile)\n",
    "conversation=conversation_data[\"conversations\"]\n",
    "                \n",
    "x=[]\n",
    "y=[]\n",
    "                \n",
    "for i in range(len(conversation)):\n",
    "    for j in range(len(conversation[i])):\n",
    "        if j<len(conversation[i])-1:\n",
    "            x.append(conversation[i][j])\n",
    "            y.append(conversation[i][j+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step 1 -Data Preprocessing -tokenize the sentence into words\n",
    "tok_x_qa=[]\n",
    "tok_y_qa=[]\n",
    "for i in range(len(x)):\n",
    "    tok_x_qa.append(nltk.word_tokenize(x[i].lower()))\n",
    "    tok_y_qa.append(nltk.word_tokenize(y[i].lower()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step 2 -Data Preprocessing-Keep only those words which are avaiable in our trained word2vec model.\n",
    "vec_x=[]\n",
    "for tok in tok_x_qa:\n",
    "    sentvec=[model_pre_process[w] for w in tok if w in model_pre_process.vocab]\n",
    "    vec_x.append(sentvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step 2 repeted for y as well\n",
    "vec_y=[]\n",
    "for tok in tok_y_qa:\n",
    "    sentvec=[model_pre_process[w] for w in tok if w in model_pre_process.vocab]\n",
    "    vec_y.append(sentvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#took ones array of length 200 \n",
    "#will use for converting variable length sequences to fixed length\n",
    "sentpadding=np.ones((300),dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentpadding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Curenly BOT can understand only till 14 characters\n",
    "for tok_vec in vec_x:\n",
    "    tok_vec[14:]=[]\n",
    "    tok_vec.append(sentpadding)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Append the sentpadding if len is less than 14\n",
    "for tok_vec in vec_x:\n",
    "    if len(tok_vec)<15:\n",
    "        for i in range(15-len(tok_vec)):\n",
    "            tok_vec.append(sentpadding)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Same has done for y\n",
    "for tok_vec in vec_y:\n",
    "    if len(tok_vec)<15:\n",
    "        for i in range(15-len(tok_vec)):\n",
    "            tok_vec.append(sentpadding)\n",
    "            \n",
    "#Preprocessing End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start Chatbot model \n",
    "#for splitting test and train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "#to initate keras model\n",
    "from keras.models import Sequential\n",
    "#to implement LSTM and RNN\n",
    "from keras.layers.recurrent import LSTM,SimpleRNN\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to split vec_x and vec_y \n",
    "#np is numpy here\n",
    "\n",
    "vec_x=np.array(vec_x,dtype=np.float64)\n",
    "vec_y=np.array(vec_y,dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use train_test_split function to split training data 80% and test data 20% and its random to avoiad bias\n",
    "x_train,x_test,y_train,y_test=train_test_split(vec_x,vec_y,test_size=0.1,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initita the Layer in Recurrent Nueral Network\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding 5 hidden layer in Neural network with required paraemeters\n",
    "model.add(LSTM(output_dim=300,input_shape=x_train.shape[1:],return_sequences=True,init=\"glorot_normal\",inner_init=\"glorot_normal\",activation=\"sigmoid\"))\n",
    "model.add(LSTM(output_dim=300,input_shape=x_train.shape[1:],return_sequences=True,init=\"glorot_normal\",inner_init=\"glorot_normal\",activation=\"sigmoid\"))\n",
    "model.add(LSTM(output_dim=300,input_shape=x_train.shape[1:],return_sequences=True,init=\"glorot_normal\",inner_init=\"glorot_normal\",activation=\"sigmoid\"))\n",
    "model.add(LSTM(output_dim=300,input_shape=x_train.shape[1:],return_sequences=True,init=\"glorot_normal\",inner_init=\"glorot_normal\",activation=\"sigmoid\"))\n",
    "model.add(LSTM(output_dim=300,input_shape=x_train.shape[1:],return_sequences=True,init=\"glorot_normal\",inner_init=\"glorot_normal\",activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use cosine_proximity as word embedding works on cosine proximity and optimizer is gradient descendants .\n",
    "model.compile(loss=\"cosine_proximity\",optimizer=\"adam\",metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model ,can take more than epoch that can increase the accuracy and more computation required\n",
    "model.fit(x_train,y_train,nb_epoch=2000,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saving the chatbot \n",
    "#we will use this trained model on input data\n",
    "model.save(\"chatbot_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
